//
//  FirebaseManagerService.swift
//  Wordy
//

import FirebaseFirestore
import FirebaseStorage
import FirebaseFunctions
import AVFoundation
import Combine

@MainActor
class FirebaseTTSManager: ObservableObject {
    static let shared = FirebaseTTSManager()
    private let db = Firestore.firestore()
    private let storage = Storage.storage()
    private let functions = Functions.functions()
    
    @Published var isLoading = false
    @Published var isPlaying = false
    @Published var currentLanguage: String?
    @Published var error: String?
    
    private var audioPlayer: AVPlayer?
    private var playerItemObserver: NSKeyValueObservation?
    
    private init() {
        print("üé§ FirebaseTTSManager —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω–æ")
    }
    
    func speak(text: String, language: String) {
        print("üé§ FirebaseTTSManager.speak() –≤–∏–∫–ª–∏–∫–∞–Ω–æ: '\(text)' (\(language))")
        
        guard !text.isEmpty else {
            print("‚ùå –ü–æ—Ä–æ–∂–Ω—ñ–π —Ç–µ–∫—Å—Ç")
            return
        }
        
        stopPlaying()
        
        isLoading = true
        error = nil
        currentLanguage = language
        
        print("üîç –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–µ—à –¥–ª—è: \(text)_\(language)")
        
        checkCache(for: text, language: language) { [weak self] cachedURL in
            DispatchQueue.main.async {
                if let url = cachedURL {
                    print("‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –≤ –∫–µ—à—ñ: \(url)")
                    self?.isLoading = false
                    self?.playAudio(from: url, language: language)
                } else {
                    print("üåê –ù–µ–º–∞—î –≤ –∫–µ—à—ñ, –≤–∏–∫–ª–∏–∫–∞—î–º–æ Cloud Function")
                    self?.generateAudioViaCloudFunction(text: text, language: language)
                }
            }
        }
    }
    
    private func checkCache(for text: String, language: String, completion: @escaping (URL?) -> Void) {
        let wordId = "\(text.lowercased().trimmingCharacters(in: .whitespaces))_\(language)"
        let docRef = db.collection("words_collection").document(wordId)
        
        docRef.getDocument { snapshot, error in
            if let error = error {
                print("‚ùå Firestore error: \(error)")
                completion(nil)
                return
            }
            
            if let data = snapshot?.data(),
               let audio = data["audio"] as? [String: String],
               let urlString = audio[language],
               let url = URL(string: urlString) {
                print("‚úÖ –ö–µ—à –∑–Ω–∞–π–¥–µ–Ω–æ: \(urlString)")
                completion(url)
            } else {
                print("‚ÑπÔ∏è –ö–µ—à –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –¥–ª—è: \(wordId)")
                completion(nil)
            }
        }
    }
    
    private func generateAudioViaCloudFunction(text: String, language: String) {
        let parameters: [String: Any] = [
            "data": [
                "word": text,
                "language": language
            ]
        ]
        
        print("üåê –í–∏–∫–ª–∏–∫–∞—î–º–æ Cloud Function: generateTTS")
        print("üì¶ –ü–∞—Ä–∞–º–µ—Ç—Ä–∏: \(parameters)")
        
        functions.httpsCallable("generateTTS").call(parameters) { [weak self] result, error in
            DispatchQueue.main.async {
                self?.isLoading = false
                
                if let error = error {
                    print("‚ùå Cloud Function error: \(error)")
                    self?.error = error.localizedDescription
                    
                    // Fallback: –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–æ–∫–∞–ª—å–Ω–∏–π AVSpeechSynthesizer
                    print("üîä Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–µ –æ–∑–≤—É—á—É–≤–∞–Ω–Ω—è")
                    self?.speakLocally(text: text, language: language)
                    return
                }
                
                guard let resultData = result?.data as? [String: Any],
                      let response = resultData["result"] as? [String: Any],
                      let audioURL = response["audioURL"] as? String,
                      let url = URL(string: audioURL.trimmingCharacters(in: .whitespaces)) else {
                    print("‚ùå Invalid response: \(String(describing: result?.data))")
                    self?.error = "–ù–µ–≤—ñ—Ä–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å —Å–µ—Ä–≤–µ—Ä–∞"
                    return
                }
                
                print("‚úÖ –û—Ç—Ä–∏–º–∞–Ω–æ –∞—É–¥—ñ–æ URL: \(audioURL)")
                self?.playAudio(from: url, language: language)
            }
        }
    }
    
    // MARK: - –õ–æ–∫–∞–ª—å–Ω–∏–π fallback
    private func speakLocally(text: String, language: String) {
        let synthesizer = AVSpeechSynthesizer()
        let utterance = AVSpeechUtterance(string: text)
        
        let languageCode = mapToAppleLanguageCode(language)
        utterance.voice = AVSpeechSynthesisVoice(language: languageCode)
        utterance.rate = 0.5
        utterance.pitchMultiplier = 1.0
        
        synthesizer.speak(utterance)
        
        // –Ü–º—ñ—Ç—É—î–º–æ —Å—Ç–∞–Ω –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è
        self.isPlaying = true
        self.currentLanguage = language
        
        // –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å–∫–∏–¥–∞—î–º–æ —á–µ—Ä–µ–∑ 2 —Å–µ–∫—É–Ω–¥–∏ (–ø—Ä–∏–±–ª–∏–∑–Ω–∏–π —á–∞—Å)
        DispatchQueue.main.asyncAfter(deadline: .now() + 2) {
            self.isPlaying = false
        }
    }
    
    private func mapToAppleLanguageCode(_ code: String) -> String {
        let mapping = [
            "uk": "uk-UA",
            "en": "en-US",
            "de": "de-DE",
            "pl": "pl-PL",
            "es": "es-ES",
            "fr": "fr-FR",
            "it": "it-IT",
            "pt": "pt-PT"
        ]
        return mapping[code] ?? "en-US"
    }
    
    private func playAudio(from url: URL, language: String) {
        print("üîä –í—ñ–¥—Ç–≤–æ—Ä—é—î–º–æ –∞—É–¥—ñ–æ: \(url.lastPathComponent)")
        
        do {
            let session = AVAudioSession.sharedInstance()
            try session.setCategory(.playback, mode: .default, options: [.mixWithOthers])
            try session.setActive(true)
        } catch {
            print("‚ö†Ô∏è Audio session error: \(error)")
        }
        
        audioPlayer?.pause()
        
        let playerItem = AVPlayerItem(url: url)
        audioPlayer = AVPlayer(playerItem: playerItem)
        
        playerItemObserver = playerItem.observe(\.status, options: [.new]) { [weak self] item, _ in
            DispatchQueue.main.async {
                switch item.status {
                case .readyToPlay:
                    print("‚ñ∂Ô∏è –ü–æ—á–∏–Ω–∞—î–º–æ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è")
                    self?.isPlaying = true
                case .failed:
                    print("‚ùå –ü–æ–º–∏–ª–∫–∞ –ø–ª–µ—î—Ä–∞")
                    self?.isPlaying = false
                    self?.error = "–ü–æ–º–∏–ª–∫–∞ –≤—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è"
                default:
                    break
                }
            }
        }
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(playerDidFinishPlaying),
            name: .AVPlayerItemDidPlayToEndTime,
            object: playerItem
        )
        
        audioPlayer?.play()
    }
    
    @objc private func playerDidFinishPlaying() {
        DispatchQueue.main.async {
            print("‚èπÔ∏è –í—ñ–¥—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            self.isPlaying = false
            self.currentLanguage = nil
        }
    }
    
    func stopPlaying() {
        audioPlayer?.pause()
        audioPlayer = nil
        playerItemObserver?.invalidate()
        playerItemObserver = nil
        isPlaying = false
        currentLanguage = nil
        NotificationCenter.default.removeObserver(self)
        
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
        } catch {
            print("‚ö†Ô∏è Deactivation error: \(error)")
        }
    }
}
